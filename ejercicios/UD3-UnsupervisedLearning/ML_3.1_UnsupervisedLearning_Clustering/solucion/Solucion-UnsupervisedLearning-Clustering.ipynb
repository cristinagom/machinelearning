{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Solución Ejercicios Clustering K-means\n",
    "#### UD3. Aprendizaxe non supervisada\n",
    "#### MP. Sistemas de Aprendizaxe Automáticos\n",
    "#### IES de Teis (Vigo), Cristina Gómez Alonso\n",
    "\n",
    "Aunque la mayoría de las aplicaciones de los algoritmos de aprendizaje automático en la actualidad se basan en el aprendizaje supervisado, la gran mayoría de los datos disponibles **no están etiquetados**. Tenemos la entrada $X$, pero no tenemos las etiquetas $y$.\n",
    "\n",
    "> [Yann LeCun]: \"If intelligence was a cake, **Unsupervised Learning** would be the **cake**, **supervised learning** would be the **icing** on the cake, and **reinforcement learning** would be the **cherry** on the cake.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**1. ¿Cuáles son algunas de las principales aplicaciones de los algoritmos de clustering?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **¿En dónde se usa?**\n",
    "\n",
    "    Estos son simples ejemplos de usos reales del clustering. Está muy ligado al Big Data, ya que el tener una gran cantidad de datos sin anotar, es necesario aplicar algún algoritmo para separar esa cantidad inmensa de datos en diferentes grupos.\n",
    "    Uno de sus mayores usos son en tareas de segmentación de mercado, donde se trata de agrupar una base de datos en distintos grupos. Cada uno de ellos estña caracterizado por unas ciertas propiedades que ayudan a describir cómo son, cómo se comportan y cuáles son sus interes, para poder oferecerles productos y servicios personalizados y adecuados a sus gustos e intereses.\n",
    "\n",
    "2. **Ejemplos:**\n",
    "\n",
    "  - Segmentación de clientes en grupos.\n",
    "  - Segmentación de productos.\n",
    "  - Segmentación de tiendas.\n",
    "  - Determinar los distintos patrones climáticos de una región.\n",
    "  - Agrupar artículos o noticias por temas.\n",
    "  - Descubrir zonas con elevadas tasas de criminalidad.\n",
    "\n",
    "\n",
    "3. **La forma en la que se realiza un clustering es:**\n",
    "\n",
    "  - Decidir el número de clusters.\n",
    "  - Formar grupos de similaridades y se asignan un centro.\n",
    "  - Medir el error de la máquina en su capacidad para encontrar el centro de los grupos.\n",
    "  - Volver a formar grupos de similaridad partiendo del centro anterior.\n",
    "  - Medir el error y agregarlo al algoritmo hasta que ya no varíe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**2. Describe 2 técnicas para seleccionar el número correcto de clústeres al usar K-Means.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Método Elbow:\n",
    "\n",
    "   - **Resumen:**\n",
    "\n",
    "      El método más antiguo para distinguir el número de clusters potencialmente correcto para el conjunto de datos que se van a analizar, cuya idea básica es especificar `K=2` como el número de clusters óptimo inicial, y luego sigue aumentando k hasta el máximo especificado estimado, y finalmente, distinguir el número de cluster óptimo correspondiente al codo. EL número k óptimo se distingue por el hecho de que antes de llegar a K, el costo disminuye rápidamente hasta el valor pico de costo, y después, de exceder k, continúa aumentado con el llamado valor \"peak\". Este cambio de en el costo, de pasar de disminuir rápidamente a poco, se le llama coda, y es ahí, en el vértice del codo, de donde se saca el valor óptimo de k.\n",
    "\n",
    "      Se tiene que calcular la distorción promedia de los clústers, que es la distancia promedia del centroide a todos los puntos del cluster y se obtiene con el algoritmo de k-means en función del número de clusters. Así, cuando se va de una situación en la que el número de clusters es inferior al correcto a una situación en la que el número es el adecuado, el valor de la dispersión disminuye bruscamente, mientras que si aumenta el número de clusters al adecuado, el valor de la dispersión se reducirña más lentamente, formando un codo en la gráfica.\n",
    "   \n",
    "   - **Ecuación:**\n",
    "\n",
    "      Este método utiliza los valores de la inercia obtenidos tras aplicar el K-means a diferente número de Clusters, siendo la inercia la suma de las distancias al cuadrado de cada objeto del Cluster a su centroide:\n",
    "      $$Inercia = \\sum_{i=0}^N {||x_i - \\mu||}^2$$\n",
    "\n",
    "   - **Representación:**\n",
    "\n",
    "      <div style=\"text-align:center\">\n",
    "         <img style=\"width:30%\" src=\"img/Elbow.png\">\n",
    "      </div>\n",
    "\n",
    "# Método Silhouette:\n",
    "\n",
    "   - **Resumen:**\n",
    "\n",
    "      El método de la silueta se denomina así porque utiliza el coeficiente de la Silhouette. Este se define como la diferencia entre la distancia media a los elementos del clúster clúster más cercano y a distancia intra-clúster media de los elementos de un clúster dividido por el máximo de los dos. En el momento que se alcance el número de clústeres óptimos para un conjunto de datos, la Dilhouette, se maximiza.\n",
    "\n",
    "      Este análisis se puede utilizar para el estudiar la distancia de separación entre los grupos resultantes. El gráfico resultante muestra una medida de qué tan cerca está cada punto en un grupo de puntos en los grupos vecinos y proporciona una forma de evaluar parámetros como el número de grupos visualmente. Esta medida tiene un rando de `[-1, 1]`.\n",
    "\n",
    "      Los coeficientes cercanos a `1` indican que la muestra está lejos de los clústers vecinos.\n",
    "      Un valor de `0` indica que la muestra está dentro o muy crca del límite de decisión entre dos clústers vecinos.\n",
    "      Los valores cercanos a `-1` indican que las muestras pueden haber sido asignadas al clúster equivocado.\n",
    "   \n",
    "   - **Ecuación:**\n",
    "\n",
    "      Este coeficiente se calcula utilizando la distancia media dentro del grupo `a` y la distancia media del grupo más cercano `b` para cada muestra. El coeficiente de silueta para una muestra es:\n",
    "      $$\\frac{(a-b)}{max(a, b)}$$\n",
    "      Para aclarar, `b` es la distancia entre una muestra y el grupo más cercano del que la muestra no forma parte. Hay que tener en cuenta que el coeficiente de silueta solo se define si el númerode etiquetas es: `2 <= n_labels <= n_samples -1`\n",
    "   - **Representación:**\n",
    "  \n",
    "      <div style=\"text-align:center\">\n",
    "         <img style=\"width:30%\" src=\"img/Silhouette.png\">\n",
    "      </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**3. Abre el fichero ClusteringMetrics.ipynb y explica que otros dos métodos adicionales existen para seleccionar el número correcto de clústers. ¿En qué consisten? Busca información al respecto.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Davies-Bouldin:\n",
    "\n",
    "- **Resumen:**\n",
    "    \n",
    "    Introducido por David L. Davis y Donald W. Donald, este es una de las medidas de evaluación de los algoritmos de clustering. Se usa conmunmente para evaluar la bondad de la división mediante un algoritmo de agrupación en clústeres de K-Means apra una cantidad determinada de clústeres.\n",
    "\n",
    "    Se calcula como la similitud promedio de cada grupo con el grupo más similar.\n",
    "\n",
    "    Se interpreta de manera que cuanto más bajo sea el índice, mejor se separan los conglomerados y mejor es el resultado del agrupamiento realizado.\n",
    "    \n",
    "- **Ecuación:**\n",
    "    \n",
    "    La expresión del índice de Davies-Bouldin se basa en los puntos promedio de cad grupo y la distancia promedio entre un punto y el centro de su grupo:\n",
    "    $$S_{DB} = \\frac{1}{K}\\sum_{k=1, j\\neq0}^K max(\\frac{\\delta_i + {\\delta_j}^2}{d(\\mu_i, \\mu_j)})$$\n",
    "    Donde k es el número de clústeres, $\\delta_i$ es la distancia promedio entre cada punto en el clúster `i` y el centroide del clúster, $\\delta_j$ es la distancia promedio entre cada punto del clúster j y el centroide del clúster, y $d(\\mu_i, \\mu_j)$ es la distancia entre los centroides de los 2 clústers.\n",
    "\n",
    "- **Representación:**\n",
    "  \n",
    "    <div style=\"text-align:center\">\n",
    "        <img style=\"width:30%\" src=\"img/Davies-Bouldin.png\">\n",
    "    </div>\n",
    "\n",
    "# V-Measure:\n",
    "\n",
    "- **Resumen:**\n",
    "\n",
    "    Este método requiere un cálculo en dos términos.\n",
    "    1. Homegeneidad: \n",
    "\n",
    "        Una agrupación perfectamente homogénea es aquella en la que cada agrupación tiene puntos de datos que pertenecen a la misma etiqueta de clase. La homogeneidad describe la cercanía del algoritmo de agrupamiento a esta perfección.\n",
    "    \n",
    "    2. Completitud:\n",
    "   \n",
    "        Una agrupación perfectamente completa es aquella en la que todos los puntos de datos que pertenecen a la misma clase se agrupan en el mismo grupo. La completitud describe la cercanía del algoritmo de agrupamiento a esta perfección.\n",
    "    \n",
    "    **Homogeneidad trivial:** Es el caso cuando el número de clústers es igual al número de puntos de datos y cada punto está axactamente en un conglomerado. Es el caso extremo cuando la homogeneidad es máxima mientras que la integridad es mínima.\n",
    "\n",
    "    <div style=\"text-align:center\">\n",
    "        <img style=\"width:30%\" src=\"img/homogenity.png\">\n",
    "    </div>\n",
    "\n",
    "    **Completitud trivial:** Es el caso cuando todos los puntos se agrupan en un solo grupo. Es el caso extremo cuando la homogeneidad es mínima y la completitud es máxima.\n",
    "\n",
    "    <div style=\"text-align:center\">\n",
    "        <img style=\"width:30%\" src=\"img/completeness.png\">\n",
    "    </div>\n",
    "\n",
    "    **Agrupamiento homogéneo perfecto:** Cuando en cada grupo los puntos de datos son de la misma etiqueta de clase.\n",
    "\n",
    "    <div style=\"text-align:center\">\n",
    "        <img style=\"width:30%\" src=\"img/homoNotcomp.png\">\n",
    "    </div>\n",
    "\n",
    "    No está completo porque no todos los puntos de la clase de datos de la misma etiqueta de clase pertenecen al mismo grupo. \n",
    "\n",
    "    **Agrupamiento perfectamente completo:** Cuando todos los puntos de datos de la misma etiqueta de clase pertenecen al mismo grupo.\n",
    "\n",
    "    <div style=\"text-align:center\">\n",
    "        <img style=\"width:30%\" src=\"img/compNothomo_2.png\">\n",
    "    </div>\n",
    "\n",
    "    Aunque este no es hgomogéneo porque el primer grupo contiene puntos de datos de muchas etiquetas de clase.\n",
    "\n",
    "- **Ecuación:**\n",
    "\n",
    "    Se define como la media armónica de la homogeneidad `h` y la completitud `c` del clúster. Ambas medidas pueden expresarse en términos de información mutua y medidas de entropía de la teoría de la información.\n",
    "\n",
    "    $$V_\\beta = (1 + \\beta) \\frac{h * c}{\\beta * h + c}$$\n",
    "\n",
    "    La homogeneidad `h` se maximiza cuando cada grupo contiene elementos de la menor cantidad posible de clases diferentes. La completitud `c` tiene como objetivo poner todos los elementos de cada clase en grupos individuales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**4. Toma como base el dataset data_Clusters.csv y aplica un algoritmo de clustering a dicho dataset. Responde a las siguientes preguntas:\n",
    "4.1. ¿Cuál es la media, max, min de cada característica?\n",
    "4.2. ¿Cuál es la distribución espacial del dataset? Obtén una representación gráfica.\n",
    "4.3. ¿Cuál es la evolución de la inertia en función de K? Obtén una representación gráfica.\n",
    "4.4. ¿Cuál es el número óptimo de clusters que obtienes según el método del Elbow y el método del Silhouette Score?\n",
    "4.5. Una vez optenido el valor óptimo de K, genera un modelo K-means y entrénalo con los datos anteriores-\n",
    "4.6. Invéntate diversas predicciones para saber en qué clúster se asigna.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hecho en el fichero \"ejercicio_4.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**5. ¿Qué otros algoritmos de clustering existen al margen del clásico K-means? Busca 2 y descríbelos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN:\n",
    "\n",
    "Es un algoritmo de cluster basado en densidad.\n",
    "\n",
    "Este algoritmo empieza en un punto arbitrario que no ha sido \"visitado\". Los vecinos de este punto se extraen usando una distancia épisilon $\\epsilon$, en donde todos los puntos que están dentro de esa distancia son puntos de vecindad.\n",
    "\n",
    "Si hay una cantidad suficiente de puntos dentro de esta vecindad, entonces comienza el proceso de agrupación y el punto de datos actual se convierte en el primer punto en el nuevo grupo. De lo contrario, el punto se etiquetará como ruido, pero en ambos casos se marca como visitado.\n",
    "\n",
    "Para el primer punto en el nuevo grupo, los puntos dentro de su distancia epsilon también se vuelven parte del mismo grupo. Este procedimiento de hacer que todos los puntos en la vecindad pertenezcan al mismo clúster se repite luego para todos los nuevos puntos que acaban de agregarse al grupo de clústers.\n",
    "Este proceso se repite hasta que se determinan todos los puntos del grupo, es decir, hasta que se han visitado y etiquetado todos los puntos dentro de la distancia epsilon del grupo.\n",
    "\n",
    "Una vez se termina con el grupo actual, se recupera y procesa un nuevo punto no visitado, lo que conduce al descubrimiento de otro grupo o ruido. Este proceso se repite hasta que todos los puntos se marcan como visitados.. Dado que al final de esto se han visitado todos los puntos, cad punto se habŕ marcado como perteneciente a un grupo o como ruído.\n",
    "\n",
    "### Ventajas\n",
    "\n",
    "Una de sus principales ventajas es que no requiere una cantidad determinada de clústeres. También identifica los valores atípicos como ruídos, a diferencia de otros que los arroja a un grupo, incluso si el punto de datos es muy diferente. Además puede encontrar clústeres de tamaño y formas muy diferentes.\n",
    "\n",
    "### Desventajas\n",
    "\n",
    "No funciona tan bien como otrso cuando los grupos tienen una densidad variable. Esto se debe a que la configuración del umbral de distancias epsilon y minPoints para identificar los puntos de vecindad variará de un grupo a otro cuando la densidad varía. Este inconveniente también ocurre con datos de dimensiones muy altas, ya que nuevamente el umbral de distancia epsilon se vuelve dificil de estimar.\n",
    "\n",
    "### Visualización\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img style=\"width:50%\" src=\"img/dbscan.png\">\n",
    "</div>\n",
    "\n",
    "# Mean-Shift Clustering:\n",
    "\n",
    "Este algoritmo es basado en una \"ventana deslizante\" que intenta encontrar áreas densas de puntos de datos. Es un algoritmo basado en el centroide, lo que significa que el objetivo es ubicar los puntos centrales de cada grupo, que funciona actualizando los candidatos para que los puntos centrales sean la media de los puntos dentro de la \"ventana deslizante\". Estas ventanas candidatas luego se filtran en una etapa de postprocesado para eliminar los duplicados, formando el conjunto final de puntos centrales y sus grupos correspondientes.\n",
    "\n",
    "Para explicar este algoritmo, se considera un conjunto de puntos en un espacio bidimensional. Se comienza con una ventana deslizante circular centrada en un punto `C`, el cual es seleccionado al azar, y que tiene un radio `r` coomo núcleo, El algoritmo implica cambiar este núcleo de forma iterativa a una región de mayor densidad en cada paso hasta la convergencia.\n",
    "\n",
    "En cada iteración, la ventana deslizante se desplaza hacia regiones de mayor densidad desplazando el punto central a la media de los puntos dentro de la ventrana. La densidad dentro de esta es proporcional al número de puntos dentro de ella. Al cambiar a la media de los puntos en la ventana, se moverá gradualmente hacia áreas de mayor densidad de puntos.\n",
    "\n",
    "Se continúa desplazando la ventana deslizante de acuerdo con la media hasta que no haya una dirección en la que un desplazamiento pueda acomodar más puntos dentro del núcleo. Este proceso se realiza con muchas ventanas hasta que todos los puntos se encuentran dentro de una ventana. Cuando avrias ventanas se superponen, se conserva la ventana que contiene la mayoeía de los puntos. Luego, los puntos de datos se agrupan de acuerdo con la ventana deslizante en la que residen. \n",
    "\n",
    "### Ventajas\n",
    "\n",
    "No necesita seleccionar un número de clústers, ya que el desplazamiento de la media lo descubre automaticamente. EL hecho de que los centros de los clústers converjan hacia los puntos de máxima densidad también es deseable, ya que es bastante intuitivo de entender y encaja bien en su sentido natural vasado en datos.\n",
    "\n",
    "### Desventajas\n",
    "\n",
    "La desventaja es que la selección del tamaño de ventana puede no ser trivial.\n",
    "\n",
    "### Visualización\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img style=\"width:40%\" src=\"img/mean-shift.png\">\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Licencia\n",
    "\n",
    "[Attributon-ShacerAlike 4.0 International](https://creativecommons.org/licenses/by-sa/4.0/)\n",
    "\n",
    "Puedes utilizar libremente este material, con las siguientes condiciones:\n",
    "\n",
    "* Atribuir la autoría a este documento.\n",
    "* Si lo utilizas y haces cambios, deberás liberarlo también bajo la misma licencia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
