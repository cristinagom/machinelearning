{"cells":[{"cell_type":"markdown","metadata":{"id":"E5ANp2r_H1p-"},"source":["# Árboles de decisión\n","#### UD2. Aprendizaxe Supervisada\n","#### MP. Sistemas de Aprendizaxe Automáticos\n","#### IES de Teis (Vigo), Cristina Gómez Alonso\n","\n","En este notebook tomaremos como referencia el material del brillante Aurelien Geron resumido por Akranz que explica como entrenar, validar y realizar predicciones con árboles de decisión tomando como base el dataset de clasificación de flores iris con la librería **Scikit-learn**.\n","\n","El dataset es original de UCI ML repository.\n","<br>Link: https://archive.ics.uci.edu/ml/datasets/iris\n","\n","Luego revisaremos el algoritmo de entrenamiento CART utilizado por `Scikit-Learn`, veremos cómo regularizar árboles y usarlos en tareas de regresión. Finalmente, analizaremos algunas de las limitaciones de los árboles de decisión.\n","\n","\n","¿Qué son los Árboles de Decisión?\n","\n","Son representaciones gráficas de posibles soluciones a una decisión basadas en ciertas condiciones. Es uno de los algoritmos de aprendizaje supervisado más utilizados en machine learning y pueden realizar tareas de clasificación o regresión. La comprensión de su funcionamiento suele ser simple y a la vez muy potente.\n","\n","Principales características de los árboles de decision:\n","* Clasifica mediane el valor de los atributos\n","* Es una técnica de clasificación muy extendida\n","* Es fácilmente entendible por personas no expertas\n","* También pueden utilizarse en técnicas de regresión como herramienta de predicción numérica para estimar valores reales (por ejemplo: ventas al mes, coste de compra de un vehículo...)\n","\n","\n","Más info:\n","* [Wikipedia](https://en.wikipedia.org/wiki/Decision_tree_learning)\n","* [Kaggle](https://www.kaggle.com/prashant111/decision-tree-classifier-tutorial)\n","\n","\n","\n","## 1. Importación de paquetes y dataset\n","\n","Para entender los árboles de decisión, comencemos por construir uno y consultar sus predicciones:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GRmElfIEH1qD"},"outputs":[],"source":["from sklearn.datasets import load_iris\n","from sklearn.tree import DecisionTreeClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EX8X2GNeH1qF"},"outputs":[],"source":["iris = load_iris()"]},{"cell_type":"markdown","source":["## 2. División del dataset"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"Lel1EicRH1qG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QQBhwwuNH1qG","outputId":"022f70f0-f1d7-4b57-8548-d05d5f1c9d7f"},"outputs":[{"data":{"text/plain":"((150, 2), (150,))"},"execution_count":178,"metadata":{},"output_type":"execute_result"}],"source":["X = iris.data[:, 2:]  # Petal length and width\n","y = iris.target\n","X.shape, y.shape"]},{"cell_type":"markdown","source":["## 3. Creación del modelo de Árboles de decisión"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"8UkZGcu4H1qH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JVG44ut1H1qI"},"outputs":[],"source":["tree_clf = DecisionTreeClassifier(max_depth=2)"]},{"cell_type":"markdown","source":["## 4. Entrenamiento"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"gxA9xixJH1qJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1wrI3S6-H1qK","outputId":"74e8590e-b7aa-492f-9255-8699abf1cec6"},"outputs":[{"data":{"text/plain":"DecisionTreeClassifier(max_depth=2)"},"execution_count":180,"metadata":{},"output_type":"execute_result"}],"source":["tree_clf.fit(X, y)"]},{"cell_type":"markdown","source":["## 5. Visualización del árbol de decisión\n","\n","Podemos visualizar el árbol de decisiones utilizando el método export_graphiz() para exportar un archivo de representación gráfica y luego transformarlo a png:"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"y2qkCy-BH1qK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0fKA4-EMH1qL"},"outputs":[],"source":["from sklearn.tree import export_graphviz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5NEYNX2zH1qM"},"outputs":[],"source":["export_graphviz(tree_clf, \n","                out_file='./img/iris_tree.dot',\n","                feature_names=iris.feature_names[2:],\n","                class_names=iris.target_names,\n","                rounded=True,\n","                filled=True)"]},{"cell_type":"markdown","metadata":{"id":"ox00VUj-H1qM"},"source":["Convertimos el archivo gráfico en un archivo .png:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JojiidkqH1qN","outputId":"0eed8cc1-b684-4951-889c-36709fe3ae69"},"outputs":[{"name":"stdout","output_type":"stream","text":["zsh:1: command not found: dot\r\n"]}],"source":["! dot -Tpng ./img/iris_tree.dot -o ./img/iris_tree.png"]},{"cell_type":"markdown","metadata":{"id":"Hc9QZBS8H1qN"},"source":["Y este es el resultado:\n","\n","![Resultado](img/iris_tree.png)"]},{"cell_type":"markdown","metadata":{"id":"a9tBJcb3H1qN"},"source":["## 8. Realización de predicciones\n","\n","Para clasificar un nuevo punto de datos, comenzamos en el nodo raíz del gráfico (en la parte superior) y respondemos las preguntas binarias hasta que llegamos a una hoja final. Esa última hoja representa la clase a la cuál se corresponde.\n","Una de las cualidades de los árboles de decisión es que requieren muy poca preparación de datos. De hecho, no requieren escalado o normalizado de las características.\n","Un nodo de árbol tiene los siguientes atributos:\n","\n","* samples (muestras): cuenta cuántas instancias de entrenamiento están sentadas en el nodo.\n","* value (valor): nos dice cuántas instancias de cada clase están configuradas en el nodo.\n","* gini: mide la impureza de los nodos (nodo puro == 0)\n","\n","La siguiente ecuación muestra cómo el algoritmo de entrenamiento calcula el índice o puntuación Gini del i-ésimo nodo:\n","\n","$$G_i=1-\\sum_{k=1}^n{p_{i,k}}^2$$\n","\n","Donde $p_{i,k}$ es la proporción o ratio de instancias de clase $k$ entre las instancias de entrenamiento en ese nodo en particular. En nuestro caso: $k \\in \\{1,2,3\\}$.\n","\n","`Scikit-learn` usa el algoritmo CART, que produce solo árboles binarios. Los nodos que no son hojas solo tienen dos hijos. Sin embargo, otros algoritmos como ID3 pueden producir árboles de decisión con nodos que tienen más de 2 hijos.\n","\n","La siguiente figura muestra los límites de decisión de nuestro árbol de decisión (los árboles de decisión tienden a crear líneas/rectángulos/cuadros/.. y dividen el espacio de características de forma lineal pero iterativamente):\n"," \n","![Boundaries](img/decision_tree_boundaries.png)\n","\n","En general, los árboles de decisión son intuitivos y sus predicciones son fácilmente interpretables. Estos tipos de modelos se denominan modelos de **caja blanca**. Por contra, los RandomForest  y las redes neuronales generalmente se consideran modelos de caja negra."]},{"cell_type":"markdown","metadata":{"id":"uc-L7UPaH1qO"},"source":["### 8.1. Estimando las probabilidades de pertenencia a cada clase\n","\n","Un árbol de decisión también puede estimar la probabilidad de que cierta instancia pertenezca a cierta clase. Simplemente devuelve el ratio o proporción de esa clase sobre la suma de todas las instancias en la hoja.\n","\n","Podemos comprobarlo con el método predict_proba de scikit-learn:\n","\n","En este ejemplo, si indicamos que la longitud del pétalo es 5 y el ancho es 1.5, la probabilidad de ser de clase 0 será 0, de clase 1 0.9 y de clase 2 0.09"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lk7vr2DOH1qP","outputId":"c6f682db-cada-47b5-d433-d1933566bb6e"},"outputs":[{"data":{"text/plain":"array([[0.        , 0.90740741, 0.09259259]])"},"execution_count":184,"metadata":{},"output_type":"execute_result"}],"source":["tree_clf.predict_proba([[5, 1.5]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pwd8tLEWH1qP","outputId":"3149918c-42fa-436d-d71d-7f49212293e1"},"outputs":[{"data":{"text/plain":"array([1])"},"execution_count":185,"metadata":{},"output_type":"execute_result"}],"source":["tree_clf.predict([[5, 1.5]])"]},{"cell_type":"markdown","metadata":{"id":"sKze1MLoH1qP"},"source":["\n","Nota: obtendremos la misma probabilidad siempre que estemos en un mismo cuadro asignado a la hoja. No importa si nuestro nuevo punto de datos se acerca a los márgenes de decisión (decision boundaries)."]},{"cell_type":"markdown","source":["## Ejercicio: Titanic\n","\n","Toma como base el dataset de pasajeros del Titanic (https://www.kaggle.com/c/titanic/data) y crea un modelo de árbol de decisión para estimar las predicciones de superviviencia de dichos pasajeros.\n","\n","Link de referencia adicional: https://medium.com/@merijoanna/learn-decision-trees-with-kaggle-example-cc03b1dbc6fa\n"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"lkrTpl5eH1qQ"}},{"cell_type":"markdown","source":["## Índice GINI\n","\n","El índice Gini es el nombre de la función de coste utilizada para evaluar las divisiones en el conjunto de datos.\n","\n","Una división en el conjunto de datos implica un atributo de entrada y un valor para ese atributo. Se puede utilizar para dividir los patrones de entrenamiento en dos grupos de filas.\n","\n","La puntuación Gini da una idea de cuán buena es una división por cuán mezcladas están las clases en los dos grupos creados por la división. Una separación perfecta da como resultado una puntuación Gini de 0, mientras que la división en el peor de los casos que da como resultado 50/50 clases en cada grupo da como resultado una puntuación de Gini de 0,5 (para un problema de 2 clases)."],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"lNB5vQQGH1qQ"}},{"cell_type":"markdown","metadata":{"id":"-jp3JCt8H1qS"},"source":["## Regularización con hiperparámetros\n","\n","**Los árboles de decisión hacen muy pocas suposiciones sobre los datos de entrenamiento**. Si no se restringe, un árbol de decisión se adaptará para ajustarse perfectamente a los datos de entrenamiento, lo que naturalmente conduce al sobreajuste (iverfitting).\n","\n","Dicho modelo a menudo se denomina modelo no paramétrico porque la cantidad de parámetros no se determina antes del entrenamiento.\n","\n","Al menos podemos restringir la profundidad máxima del árbol de decisión, entre otros hiperparámetros de regularización:\n","\n","* min_samples_split: el número mínimo de muestras que debe tener un nodo para que se divida.\n","* min_samples_leaf: El número mínimo de muestras que debe tener una hoja.\n","* min_weight_fraction_leaf: mean_samples_leaf como una fracción.\n","* max_leaf_nodes: el número máximo de nodos hoja.\n","* max_features: el número máximo de características que se evalúan para cualquier división.\n","\n","La siguiente figura muestra dos árboles de decisión entrenados en el mismo conjunto de datos, el de la izquierda representa un árbol de decisión entrenado sin restricciones y el de la derecha se regulariza mediante el hiperparámetro min_samples_leaf: \n","\n","![RegularizedTree](img/regularized_tree.png)"]},{"cell_type":"markdown","metadata":{"id":"rqT4CYheH1qS"},"source":["## Ejemplo de Arboles de Decisión para Regresión\n","\n","Los árboles de decisión también son capaces de realizar tareas de regresión."]},{"cell_type":"markdown","metadata":{"id":"XE_vDa-rH1qV"},"source":["## Inestabilidad\n","\n","Los árboles de decisión tienen algunas limitaciones:\n","\n","* Los árboles de decisión prefieren los límites de decisión ortogonales, lo que los hace sensibles a la rotación del conjunto de entrenamiento. Una forma de limitar este problema es usar PCA (Análisis de Componentes Principales) que a menudo da como resultado una mejor orientación de los datos de entrenamiento.\n","* Los árboles de decisión son sensibles a pequeñas variaciones en los datos de entrenamiento. De hecho, debido a que scikit-learn usa optimización estocástica, es posible que obtenga diferentes modelos para el mismo conjunto de datos de entrenamiento.\n","\n","Random Forests puede resolver este problema promediando la predicción entrante de muchos árboles de decisión. \n"]},{"cell_type":"markdown","metadata":{"id":"RBExKyRaH1qR"},"source":["## Complejidad computational\n","\n","Hacer una predicción requiere que vayamos desde la raíz hasta la última hoja.\n","\n","Los árboles de decisión están aproximadamente equilibrados, por lo que atravesar el árbol de decisión requiere recorrer aproximadamente $O(log_{2}(m))$. Dado que cada nodo requiere verificar el valor de una sola característica, el tiempo de ejecución de la inferencia general es $O(log_{2}(m))$. Lo que hace que el algoritmo sea independiente del número de características. Por lo tanto, las predicciones son realmente rápidas, incluso cuando el algoritmo se ocupa de una gran cantidad de características.\n","\n","El algoritmo de entrenamiento compara todas las características (excepto si se establece `max_features`) en todas las muestras en cada nodo, lo que da como resultado una complejidad de entrenamiento de $O(n \\times mlog_2(m))$.\n","\n","Para conjuntos de entrenamiento pequeños (menos de unos pocos miles), scikit-learn puede acelerar el entrenamiento mediante la clasificación previa de los datos. "]},{"cell_type":"markdown","metadata":{"id":"KguR0QJLH1qR"},"source":["## EXTRA: The CART Training Algorithm\n","\n","Scikit-Learn uses the Classification and Regression Tree (CART) algorithm to train decision trees (also called \"growing\" trees). The algorithm works by first splitting the training set by feature $k$ and threshold $t_k$.\n","\n","It chooses $k$ and $t_k$ by searching for the $(k,t_k)$ that produce the purest subsets weighted by their size.\n","\n","The following figure gives the loss function that CART tries to minimize:\n","\n","$$J(k,t_k)=\\frac{m_{left}}{m}G_{left} + \\frac{m_{right}}{m}G_{right}$$\n","\n","Where:\n","- $G_{left/right}$ measures the resulted impurity in the left/right subsets.\n","- $m_{left/right}$ correspond to the number of instances in the left/right subsets.\n","\n","Once the CART algorithm successfully split the initial training data into two subsets, it does the same thing to both subsets. It stops recursing once it reaches the maximum allowed tree depth (the `max_depth` hyper-parameter), or if it cannot find a split that reduces impurity.\n","\n","Other hyper-parameters that control stopping include: `min_samples_split`, `min_samples_leaf`, `min_weight_fraction_leaf`, `max_leaf_nodes`.\n","\n","The CART algorithm is greedy in the sense that it doesn't care if its current split will lead to an optimal downstream leaf. It only cares about finding the best possible split at the current leaf. In that sense, it doesn't necessarily result in an optimal solution.\n","\n","Unfortunately, finding the optimal tree is known to be an **NP-Complete** problem with a complexity of $O(exp(m))$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yDZ9jT4gH1qS"},"outputs":[],"source":["import numpy as np\n","from sklearn.tree import DecisionTreeRegressor\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rG3nVHySH1qS"},"outputs":[],"source":["# First we want to generate a noisy quadratic dataset\n","X = np.linspace(start=0, stop=1, num=500)\n","y = (X-0.5)**2 + np.random.randn(500)/50."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2X8oxvRxH1qT","outputId":"0871d556-7cdb-4422-fba2-ec635ccb9140"},"outputs":[{"data":{"text/plain":"<matplotlib.collections.PathCollection at 0x7f8349f48070>"},"execution_count":188,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plt.scatter(X, y, s=1.5, c='red')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z8Krhab5H1qT"},"outputs":[],"source":["tree_reg = DecisionTreeRegressor(max_depth=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JjUf2Ir_H1qT","outputId":"84d3ad43-61d4-4dd7-ebf0-36b22772435c"},"outputs":[{"data":{"text/plain":"DecisionTreeRegressor(max_depth=2)"},"execution_count":190,"metadata":{},"output_type":"execute_result"}],"source":["tree_reg.fit(X[..., None], y[..., None])"]},{"cell_type":"markdown","metadata":{"id":"YqddoAtTH1qT"},"source":["Si comprobamos el árbol resultante:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y7PZlgdlH1qU"},"outputs":[],"source":["export_graphviz(tree_reg, \n","                out_file='./img/reg_tree.dot',\n","                feature_names=['X'],\n","                class_names=['y'],\n","                rounded=True,\n","                filled=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KGDpCVn4H1qU","outputId":"8ee87a5c-8f05-4dfc-ea62-01689c725f60"},"outputs":[{"name":"stdout","output_type":"stream","text":["zsh:1: command not found: dot\r\n"]}],"source":["! dot -Tpng ./img/reg_tree.dot -o ./img/reg_tree.png"]},{"cell_type":"markdown","metadata":{"id":"P62A8mHnH1qU"},"source":["![RegressionTree](img/reg_tree.png)\n","\n","Este árbol se parece mucho al árbol de clasificación que creamos anteriormente. La principal diferencia es que en lugar de predecir una clase para cada nodo, predice un valor. La predicción representa el valor objetivo promedio para el grupo en la hoja.\n","\n","A medida que aumentamos el hiperparámetro `max_ depth`, proporcionamos más flexibilidad al árbol de regresión, a continuación se muestran las predicciones del árbol en rojo: \n","\n","![RegressionTrees](img/regression_trees.png)\n","\n","El algoritmo CART funciona casi igual que antes, pero en lugar de buscar una división que minimice la impureza, busca una división que produzca muestras equilibradas por hoja y minimice $MSE$.\n","\n","Mostramos la función de coste que el algoritmo intenta minimizar: \n","\n","$$J(k,t_k)=\\frac{m_{left}}{m}MSE_{left} + \\frac{m_{right}}{m}MSE_{right} \\\\ MSE=\\frac{1}{m}\\sum_{i=1}^{m}(\\hat{y}_{i}-y_{i})^{2}$$\n","\n","Al igual que la clasificación, los árboles de regresión son propensos a sobreajustar los datos de entrenamiento, sin ninguna regularización, terminamos con el gráfico de la izquierda y al configurar `min_samples_leaf=10` se produce un modelo mucho más razonable: \n","\n","![Regularizing](img/regularizing_trees.png)"]},{"cell_type":"markdown","metadata":{"id":"ZXUn6BsDH1qd"},"source":["---"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"colab":{"name":"8.1.Supervised-DecisionTrees-RandomForest.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}